ollama pull llama3.1
pip install --no-cache-dir -r requirements.txt
fastapi run ./app/main.py